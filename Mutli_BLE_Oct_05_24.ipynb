{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09317e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "# from celluloid import Camera # getting the camera\n",
    "from itertools import permutations\n",
    "from IPython.display import HTML\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291e2bc-5dce-4eaf-bdb9-08b044a1f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48651395",
   "metadata": {},
   "source": [
    "### loadBTdata.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981474d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBT(dir):\n",
    "    \n",
    "    dfs = pd.DataFrame()\n",
    "    filenames = [file\n",
    "                 for path, subdir, files in os.walk(dir)\n",
    "                 for file in glob(os.path.join(path, \"*.txt\"))]\n",
    "    \n",
    "#     print(filenames)\n",
    "    \n",
    "    if len(filenames)==0:\n",
    "        print(\"No data in \" + dir)\n",
    "        \n",
    "    for fname in filenames:\n",
    "\n",
    "        print(fname)\n",
    "        pi_name = fname.split('/')[5][2:5]\n",
    "        data = pd.read_csv(fname,sep=',',header=None, names=[\"Time\",\"ID\",\"RSSI\"])\n",
    "        data[\"PI\"] = pi_name\n",
    "        dfs = pd.concat([dfs,data],axis=0, ignore_index=True)\n",
    "    \n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs_sorted = dfs.sort_values(dfs.columns[0], ascending = True)\n",
    "    dfs_sorted = dfs_sorted.reset_index(drop=True)\n",
    "        \n",
    "    return dfs_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c075ed",
   "metadata": {},
   "source": [
    "### DistanceMeasures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistance(startPoint, endPoint):\n",
    "    return np.sqrt(((startPoint[0]-endPoint[0])**2)+((startPoint[1]-endPoint[1])**2))\n",
    "\n",
    "def getSideFromRadius(Radius):\n",
    "    \n",
    "#     scale_factor = 1144/33.4772\n",
    "    scale_factor = (955 - 130)/33.4772\n",
    "    # 2m is the approximated distance of waist to drop ceiling for all participants.\n",
    "    # 1144/33.4772 was emprically found to convert distances in real world to pixel distances.\n",
    "    # It is function of input image/map resoloution.\n",
    "    \n",
    "    ceilingToWaist = 2 * scale_factor\n",
    "     \n",
    "    return int(np.sqrt(np.abs((Radius**2)-(ceilingToWaist**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb05e61",
   "metadata": {},
   "source": [
    "### EP6Partitions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoom(Loc):\n",
    "    \n",
    "    x=Loc[0]\n",
    "    y=Loc[1]\n",
    "    \n",
    "    if 350 < x < 430 and 310 < y < 920:\n",
    "        room = 'Activity Studio'\n",
    "        \n",
    "    elif 620 < x < 670 and 200 < y < 950:\n",
    "        room = 'LC'\n",
    "        \n",
    "    elif 1060 < x < 1260 and 200 < y < 950:\n",
    "        room = 'RC'    \n",
    "        \n",
    "    elif 600 < x < 1210 and 130 < y < 200:\n",
    "        room = 'Kitchen' \n",
    "        \n",
    "    elif 700 < x < 1100 and 680 < y < 800:\n",
    "        room='Lounge'\n",
    "        \n",
    "    elif 1400 < x < 1480 and 320 < y < 730:\n",
    "        room='Staff Zone'  \n",
    " \n",
    "    else:\n",
    "        room='Transition Zones'\n",
    "        \n",
    "    return room"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882d2ce",
   "metadata": {},
   "source": [
    "### LocateMe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82841efb-185d-413c-b1a8-2e87103d9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locator(BLE_DATA,sTime,eTime):\n",
    "        \n",
    "    import datetime\n",
    "    # You need to pass a csv file into the form of Time (timestamp form), ID, RSSi and PI value into the locator function\n",
    "    # The locator function returns a dataframe with location, rooms and the time at that location\n",
    "\n",
    "    BLE_DATA = pd.read_csv(BLE_DATA + '.csv')\n",
    "    # The selected hyeprparameters are as follows based on our grid search optimization technique\n",
    "\n",
    "    # startTime = BLE_DATA['Time'].tolist()[0]  \n",
    "    # endTime = BLE_DATA['Time'].tolist()[-1] \n",
    "\n",
    "    startTime = datetime.datetime(int(date.split(\"/\")[0]), int(date.split(\"/\")[1]), int(date.split(\"/\")[2]), int(sTime.split(\":\")[0]), int(sTime.split(\":\")[1]), int(sTime.split(\":\")[2])).timestamp()  \n",
    "    endTime = datetime.datetime(int(date.split(\"/\")[0]), int(date.split(\"/\")[1]), int(date.split(\"/\")[2]), int(eTime.split(\":\")[0]), int(eTime.split(\":\")[1]), int(eTime.split(\":\")[2])).timestamp() \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    directory = '/opt/scratchspace/SSAGHAF/'\n",
    "    # Loading Pi X and Y Locations on Map\n",
    "    locations = np.loadtxt('PiLocations.csv', delimiter = ',', dtype = {'names': ('Pi', 'X', 'Y'),'formats': ('i','i','i')}, skiprows = 1)\n",
    "    Locations = {}\n",
    "    \n",
    "    for location in locations:\n",
    "        Locations[location[0]] = (location[1], location[2])\n",
    "        \n",
    "\n",
    "    tframe = 1         # 5s was selected as the window length ########################################################################\n",
    "    RHSI_METHOD = 1    # RHSI-Edge == 1 and RHSI-Agg == 0    ########################################################################\n",
    "    SS = 1             # Slide = 1 and Step = 2              ########################################################################\n",
    "    \n",
    "    nextp = startTime + tframe\n",
    "    sTime = startTime\n",
    "    location = []\n",
    "    Time_loc = []\n",
    "    rooms = []\n",
    "    path_x = []\n",
    "    path_y = []\n",
    "    HITPI_IDs = []\n",
    "    NUM_HITS = []\n",
    "    \n",
    "    NPT = []\n",
    "    NHT = []\n",
    "    \n",
    "    scale_factor = (955 - 130)/33.4772\n",
    "    \n",
    "    while nextp <= endTime:\n",
    "        \n",
    "        temp = BLE_DATA[(BLE_DATA['Time'] >= sTime) & (BLE_DATA['Time'] <= nextp)]\n",
    "\n",
    "        # Choose the moving type to be slide(1)/step(2)\n",
    "        \n",
    "        # The best method based on the hyperparameter tuning was the step method so we can put SS = 2\n",
    "        # Also the best weight set was S6 which is provided below\n",
    "        \n",
    "        W = [0.6, 0.4, 0.0]\n",
    "        w1, w2, w3  = W[0], W[1], W[2]\n",
    "        \n",
    "        if SS == 1:\n",
    "        \n",
    "            sTime = sTime + 1\n",
    "            nextp = sTime + tframe\n",
    "            \n",
    "        else:\n",
    "\n",
    "            sTime = sTime + tframe\n",
    "            nextp = nextp + tframe\n",
    "            \n",
    "        \n",
    "        numberOfCircles = 0\n",
    "        radii = []\n",
    "        RADIUSINM = []\n",
    "        \n",
    "        HitPiIDs,NumOfHits = np.unique(temp['PI'],return_counts=True)\n",
    "       \n",
    "#         print(HitPiIDs)\n",
    "#         len(HitPiIDs)\n",
    "        \n",
    "        N = 3.5   # N = 3.5 is a function of environment (Hyperparameter)   \n",
    "    \n",
    "        NP = len(HitPiIDs) # number of Pi's\n",
    "        \n",
    "        if NP == 0:\n",
    "            NH = 0 # max number of hits\n",
    "        else:\n",
    "            NH = np.max(NumOfHits)\n",
    "        \n",
    "        for PiID in HitPiIDs:\n",
    "            \n",
    "            RSSI = temp[temp['PI']==PiID].RSSI.mean()\n",
    "            radiusInM = 10 ** ((-73 - RSSI)/(10 * N)) # You hard code the M1RSSI into -73dbm\n",
    "            \n",
    "            if radiusInM > 10:\n",
    "                radiusInM = 10\n",
    "                \n",
    "            RADIUSINM.append(radiusInM)\n",
    "            radii.append(getSideFromRadius(int(radiusInM * scale_factor))) \n",
    "                    \n",
    "        radii = np.array(radii)\n",
    "        \n",
    "        \n",
    "        if len(HitPiIDs) == 0:\n",
    "\n",
    "            center_coordinates = (np.nan, np.nan) #(1160,405) modified to nan - it does not make sense to initialize randomly when there is no information\n",
    "        \n",
    "        if len(HitPiIDs) == 1:\n",
    "            \n",
    "            Pi = int(PiID)\n",
    "            X, Y = Locations[Pi]\n",
    "            center_coordinates = (int(X * 1830/2432), int(Y * 1167/1632))\n",
    "            radius = radii[0]\n",
    "        \n",
    "        if len(HitPiIDs) > 1:\n",
    "\n",
    "            perm = permutations(range(0,len(HitPiIDs)), 2)\n",
    "            perm = list(perm)\n",
    "            estimatedLocation = np.zeros((len(perm),2))\n",
    "            weight = np.zeros(len(perm))\n",
    "            \n",
    "            \n",
    "            # Method 1 -- RHSI-Agg: Method number: 0\n",
    "            \n",
    "            if RHSI_METHOD == 0:\n",
    "            \n",
    "                for n in range(0,len(perm)):\n",
    "\n",
    "                    Pi1 = int(HitPiIDs[perm[n][0]])\n",
    "                    Pi2 = int(HitPiIDs[perm[n][1]])\n",
    "                    X1, Y1 = Locations[Pi1][0] * 1830/2432, Locations[Pi1][1] * 1167/1632\n",
    "                    X2, Y2 = Locations[Pi2][0] * 1830/2432, Locations[Pi2][1] * 1167/1632\n",
    "                    r1 = radii[perm[n][0]]\n",
    "                    r2 = radii[perm[n][1]]\n",
    "\n",
    "                    estimatedLocation[n,:] = [int(X1+(r1/(r1+r2))*(X2-X1)), int(Y1+(r1/(r1+r2))*(Y2-Y1))] \n",
    "                    weight[n] = NumOfHits[perm[n][0]] + NumOfHits[perm[n][1]]\n",
    "\n",
    "                weighted_loc = estimatedLocation * weight[:,None]\n",
    "                weighted_sum_x = np.sum(weighted_loc[:,0]) / np.sum(weight)\n",
    "                weighted_sum_y = np.sum(weighted_loc[:,1]) / np.sum(weight)\n",
    "                center_coordinates = (int(weighted_sum_x), int(weighted_sum_y))\n",
    "                radius = int(1.5 * scale_factor)\n",
    "\n",
    "\n",
    "            # Method 2 -- RHSI-Edge: Method number: 1\n",
    "            else:\n",
    "    \n",
    "                for n in range(0,len(perm)):\n",
    "\n",
    "                    Pi1 = int(HitPiIDs[perm[n][0]])\n",
    "                    Pi2 = int(HitPiIDs[perm[n][1]])\n",
    "                    X1, Y1 = Locations[Pi1][0] * 1830/2432, Locations[Pi1][1] * 1167/1632\n",
    "                    X2, Y2 = Locations[Pi2][0] * 1830/2432, Locations[Pi2][1] * 1167/1632\n",
    "\n",
    "                    weight[n] = NumOfHits[perm[n][0]] + NumOfHits[perm[n][1]]\n",
    "                    r1 = getSideFromRadius(int(RADIUSINM[perm[n][0]] * NumOfHits[perm[n][0]]/weight[n] * scale_factor))\n",
    "                    r2 = getSideFromRadius(int(RADIUSINM[perm[n][1]] * NumOfHits[perm[n][1]]/weight[n] * scale_factor))    \n",
    "\n",
    "\n",
    "                    estimatedLocation[n,:] = [int(X1+(r1/(r1+r2))*(X2-X1)), int(Y1+(r1/(r1+r2))*(Y2-Y1))] \n",
    "\n",
    "                weighted_loc = estimatedLocation\n",
    "                weighted_sum_x = np.sum(weighted_loc[:,0]) / len(weighted_loc[:,0])\n",
    "                weighted_sum_y = np.sum(weighted_loc[:,1]) / len(weighted_loc[:,1])\n",
    "                center_coordinates = (int(weighted_sum_x), int(weighted_sum_y))\n",
    "                radius = int(1.5 * scale_factor)\n",
    "            \n",
    "            \n",
    "        if np.isnan(center_coordinates[0]) == False and np.isnan(center_coordinates[1]) == False:\n",
    "            \n",
    "            if len(location) >= 2:\n",
    "                \n",
    "                if computeDistance((location[-1][0], location[-1][1]), (location[-2][0], location[-2][1]))!=0:\n",
    "                    \n",
    "                    x_MA = w1*center_coordinates[0] + w2*location[-1][0] + w3*location[-2][0]\n",
    "                    y_MA = w1*center_coordinates[1] + w2*location[-1][1] + w3*location[-2][1]\n",
    "                    center_coordinates = (x_MA, y_MA)\n",
    "            \n",
    "            \n",
    "                \n",
    "            location.append(center_coordinates)\n",
    "            rooms.append(getRoom(center_coordinates))\n",
    "            Time_loc.append(int(nextp))\n",
    "            HITPI_IDs.append(HitPiIDs)\n",
    "            NUM_HITS.append(NumOfHits)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(location) >= 2:\n",
    "\n",
    "                location.append(location[-1])\n",
    "                rooms.append(rooms[-1])\n",
    "                Time_loc.append(Time_loc[-1] + 1)\n",
    "                HITPI_IDs.append(HITPI_IDs[-1])\n",
    "                NUM_HITS.append(NUM_HITS[-1])\n",
    "\n",
    "            \n",
    "            \n",
    "        data = {'location': location, 'rooms': rooms, 'time': Time_loc, 'PI': HITPI_IDs, '#Hits': NUM_HITS}\n",
    "        dataframe = pd.DataFrame(data)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bc2df-491c-40f2-ae64-62221f53bc5d",
   "metadata": {},
   "source": [
    "## Step II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa37ab4-7c4b-4582-8d0d-67d030ca2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLE_DATA_SORTED = pd.read_csv('BLE_DATA_SORTED.csv')\n",
    "BLE_DATA_SORTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb66821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sTime = \"17:47:39\"\n",
    "# eTime = \"17:48:59\"\n",
    "\n",
    "date = '2023/12/8'\n",
    "sTime = \"17:47:00\"\n",
    "eTime = \"17:49:00\"\n",
    "\n",
    "dataframe = locator('BLE_DATA_SORTED', sTime,eTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = dataframe.copy()\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e2ac8-b339-41af-a80a-7ed013f2071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/opt/scratchspace/SSAGHAF/'\n",
    "# Loading Pi X and Y Locations on Map\n",
    "locations = np.loadtxt('PiLocations.csv', delimiter = ',', dtype = {'names': ('Pi', 'X', 'Y'),'formats': ('i','i','i')}, skiprows = 1)\n",
    "Locations = {}\n",
    "\n",
    "Pi, X, Y = [], [], []\n",
    "\n",
    "for location in locations:\n",
    "    Pi.append(location[0])\n",
    "    X.append(location[1])\n",
    "    Y.append(location[2])\n",
    "    \n",
    "    \n",
    "data = {'Pi': Pi, 'X': X, 'Y': Y}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(\"ep6_floorplan_measured_half_gridded_1_meter.jpg\", cv2.IMREAD_COLOR)\n",
    "img = cv2.resize(img, (610*3, 389*3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 10))\n",
    "# plt.imshow(img)\n",
    "\n",
    "\n",
    "wid = img.shape[1]\n",
    "hgt = img.shape[0]\n",
    "\n",
    "print(str(wid) + \"x\" + str(hgt))\n",
    "\n",
    "\n",
    "\n",
    "color=[0,0,255] \n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    image = cv2.circle(img, (int(df['X'][i] * 1830/2432), int(df['Y'][i] * 1167/1632)), 10, color , -1)\n",
    "#     image = cv2.putText(image, str(df['Pi'][i]), (int(df['X'][i] * 1830/2432) + 10, int(df['Y'][i] * 1167/1632) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706a424-fa3f-4fcb-a38f-8859c92b561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RC real data\n",
    "\n",
    "color=[255, 0, 0] \n",
    "\n",
    "X, Y, T = [], [], []\n",
    "\n",
    "for i in range(0, 15):\n",
    "    \n",
    "    image = cv2.circle(image, (1170, 930 - i*50), 10, color , -1)\n",
    "    X.append(1170)\n",
    "    Y.append(925 - i*52)\n",
    "    T.append(5 + i*5)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image)\n",
    "\n",
    "Ground_Truth = {'X': X, 'Y': Y, 'T': T}\n",
    "df_GT = pd.DataFrame(Ground_Truth)\n",
    "df_GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd60c98-8585-472c-af28-dcefa689bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "# import pytz  # You may need to install this module using: pip install pytz\n",
    "\n",
    "# def convert_gmt_to_est(gmt_time_str):\n",
    "#     # Parse the input string as a datetime object in GMT\n",
    "#     gmt_time = datetime.strptime(gmt_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "#     gmt_time = pytz.utc.localize(gmt_time)\n",
    "\n",
    "#     # Define the time zone for Eastern Standard Time (EST)\n",
    "#     est_timezone = pytz.timezone('US/Eastern')\n",
    "\n",
    "#     # Convert GMT time to EST\n",
    "#     est_time = gmt_time.astimezone(est_timezone)\n",
    "\n",
    "#     return est_time.strftime('%Y-%m-%d %H:%M:%S %Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e13f85-bd68-4326-8702-80a5571b5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# gmt_time_str = '2023-12-08 22:29:28'\n",
    "# est_time_str = convert_gmt_to_est(gmt_time_str)\n",
    "# print(f'GMT Time: {gmt_time_str}')\n",
    "# print(f'EST Time: {est_time_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99cd6b7-06a8-4767-aaec-c8a05747d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date = '2022/04/22'\n",
    "# date = '2023/12/8'\n",
    "\n",
    "# # # time interval and participant Mac ID -------------------------------------------------- LC\n",
    "# # sTime = \"16:21:40\"\n",
    "# # eTime = \"16:30:50\"\n",
    "\n",
    "# # # Mac: \"ef:d4:e6:78:1b:80\"  #Green - not working\n",
    "# # # Mac: \"de:28:8e:55:25:67\"  #Red - not working\n",
    "# # Mac = \"fe:a1:de:0b:9d:a7\"  #Blue\n",
    "\n",
    "\n",
    "# # # # time interval and participant Mac ID -------------------------------------------------- RC\n",
    "# sTime = \"17:30:00\"\n",
    "# eTime = \"17:33:00\"\n",
    "\n",
    "# # Mac = \"e6:80:b8:03:0b:2e\" # Soheil\n",
    "# Mac = \"e7:fe:51:ec:25:c4\" # Barun\n",
    "\n",
    "# # # # time interval and participant Mac ID -------------------------------------------------- Kitchen\n",
    "# # sTime = \"16:08:20\"\n",
    "# # eTime = \"16:17:50\"\n",
    "\n",
    "# # # Mac: \"ef:d4:e6:78:1b:80\"  #Red - not working\n",
    "# # # Mac: \"de:28:8e:55:25:67\"  #Green - not working\n",
    "# # Mac = \"fe:a1:de:0b:9d:a7\"  #Blue\n",
    "\n",
    "\n",
    "# # # time interval and participant Mac ID ---------------- X - 180p ---------------------------------- Lobby\n",
    "# # sTime = \"16:36:00\"\n",
    "# # eTime = \"16:38:30\"\n",
    "\n",
    "# # # Mac = \"de:28:8e:55:25:67\"  # Red\n",
    "# # Mac = \"ef:d4:e6:78:1b:80\"  # Green\n",
    "# # # Mac = \"fe:a1:de:0b:9d:a7\"  # Blue\n",
    "\n",
    "\n",
    "# # # Activity Area Participants -------------------------  X + 50p ------------------------- Activity Area\n",
    "# # sTime = \"15:54:30\"\n",
    "# # eTime = \"16:03:30\"\n",
    "\n",
    "\n",
    "# # Mac = \"fe:a1:de:0b:9d:a7\" # Blue\n",
    "# # # Mac = \"ef:d4:e6:78:1b:80\" # Red\n",
    "# # # Mac = \"de:28:8e:55:25:67\" # green\n",
    "\n",
    "# wSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbea6ea-02c5-47fd-8f59-c0e0c475c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location, rooms, Time_loc, NPT, NHT, Unique_IDs = locator(date,sTime,eTime,Mac,wSize)\n",
    "# extractedData = {'location': location, 'rooms': rooms, 'Pis': NPT, 'Hits': NHT, 'time': Time_loc}\n",
    "# df = pd.DataFrame(extractedData)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023c872-44f1-48bc-8221-3852ce5a3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7adf2-c174-4f89-84e9-f33ab1629dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dfp['rooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6fe99-20ad-4f16-8ca2-3fcad91c069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "color=[255,0,0] \n",
    "\n",
    "X, Y , R, T, NP, NH = [], [], [], [], [], []\n",
    "\n",
    "for i in range(0,len(dfp['location'])):    \n",
    "\n",
    "    X.append(dfp['location'][i][0])\n",
    "    Y.append(dfp['location'][i][1]) \n",
    "    R.append(dfp['rooms'][i])\n",
    "    T.append(dfp['time'][i])\n",
    "            \n",
    "data = {'X': X, 'Y': Y, 'R': R, 'T': T}\n",
    "dfm = pd.DataFrame(data)  \n",
    "time_list = dfm['T'] - dfm['T'][0]\n",
    "dfm['T'] = np.array(time_list)\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b279880-e615-4af7-bcf5-93b7e42352cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y , R, T, NP, NH = [], [], [], [], [], []\n",
    "\n",
    "# for i in range(0,len(dfm)-1):\n",
    "#     if computeDistance((dfm['X'][i], dfm['Y'][i]), (dfm['X'][i+1], dfm['Y'][i+1]))!=0:\n",
    "\n",
    "#         X.append(dfm['X'][i])\n",
    "#         Y.append(dfm['Y'][i])\n",
    "#         R.append(dfm['R'][i])\n",
    "#         T.append(dfm['T'][i])\n",
    "#         # NP.append(dfm['Pis'][i])\n",
    "#         # NH.append(dfm['Hits'][i])\n",
    "\n",
    "# X.append(dfm['X'][len(dfm)-1])\n",
    "# Y.append(dfm['Y'][len(dfm)-1])\n",
    "# R.append(dfm['R'][len(dfm)-1])\n",
    "# T.append(dfm['T'][len(dfm)-1])\n",
    "        \n",
    "# # data = {'X': X, 'Y': Y, 'R': R, 'T': T, 'Pis': NP, 'Hits': NH}\n",
    "# data = {'X': X, 'Y': Y, 'R': R, 'T': T}\n",
    "# dfm = pd.DataFrame(data)\n",
    "\n",
    "# T = dfm['T'].diff()\n",
    "# T[0] = 0\n",
    "\n",
    "# # data = {'X': X, 'Y': Y, 'R': R, 'T': T, 'Pis': NP, 'Hits': NH}\n",
    "# data = {'X': X, 'Y': Y, 'R': R, 'T': T}\n",
    "# dfm = pd.DataFrame(data)\n",
    "\n",
    "# dfm['T'] = dfm['T'].cumsum()\n",
    "# dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13910c-2591-4b16-b463-2aaf9e3ba9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor(len(dfm)/len(df_GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccbd2c-b63c-4cfe-8f67-b3955efbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(len(df_GT)/len(dfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad26808-0851-43f2-826f-c48bc2770bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "XA, YA, T = [], [], []\n",
    "\n",
    "inner_counter = 0\n",
    "\n",
    "for i in range(1,len(df_GT)):\n",
    "\n",
    "    if len(dfm)>=len(df_GT):\n",
    "\n",
    "        dynamic_interval = np.floor(len(dfm)/len(df_GT))\n",
    "\n",
    "        print(dynamic_interval)\n",
    "        dfm_reduced = dfm[int((i-1)*dynamic_interval):int(i*dynamic_interval)]\n",
    "        print(dfm_reduced)\n",
    "    \n",
    "        if len(dfm_reduced) != 0:\n",
    "            XA.append(dfm_reduced['X'].mean())\n",
    "            YA.append(dfm_reduced['Y'].mean())\n",
    "        else:\n",
    "            XA.append(XA[-1])\n",
    "            YA.append(YA[-1])\n",
    "            \n",
    "        T.append(i*dynamic_interval)\n",
    "       \n",
    "    else:\n",
    "\n",
    "        dynamic_interval = np.ceil(len(df_GT)/len(dfm))\n",
    "        \n",
    "        counter = 0\n",
    "    \n",
    "        while counter < dynamic_interval:\n",
    "            \n",
    "            XA.append(dfm['X'][inner_counter])\n",
    "            YA.append(dfm['Y'][inner_counter])\n",
    "            T.append(dfm['T'][inner_counter])\n",
    "            counter = counter + 1\n",
    "\n",
    "        inner_counter = inner_counter + 1\n",
    "        \n",
    "        print(inner_counter)\n",
    "        if inner_counter >= len(dfm):\n",
    "            break\n",
    "        \n",
    "\n",
    "if len(dfm)>=len(df_GT):\n",
    "    \n",
    "    print(dfm.iloc[-2:])\n",
    "    XA.append(dfm['X'].iloc[-2:].mean())\n",
    "    YA.append(dfm['Y'].iloc[-2:].mean())\n",
    "    T.append((i+1)*dynamic_interval)\n",
    "\n",
    "else:\n",
    "    print('dfm legnth was smaller')\n",
    "\n",
    "\n",
    "        \n",
    "data = {'X': XA, 'Y': YA, 'T': T}\n",
    "dfp = pd.DataFrame(data)\n",
    "dfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a283553-0b7f-4829-ab23-89573ab1c275",
   "metadata": {},
   "source": [
    "# Check the accuracy of the estimated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7aa6ca-7488-437a-9991-e6645d40f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfp.copy()\n",
    "\n",
    "if len(dfm) > len(df_GT):\n",
    "\n",
    "    XA, YA, T = [], [], []\n",
    "\n",
    "    dynamic_interval = np.floor(len(dfm)/len(df_GT))\n",
    "    \n",
    "    for i in range(1,len(df_GT)):\n",
    "    \n",
    "        print(i)\n",
    "        dfm_reduced = dfm[int((i-1)*dynamic_interval):int(i*dynamic_interval)]\n",
    "        print(dfm_reduced)\n",
    "    \n",
    "        if len(dfm_reduced) != 0:\n",
    "            XA.append(dfm_reduced['X'].mean())\n",
    "            YA.append(dfm_reduced['Y'].mean())\n",
    "        else:\n",
    "            XA.append(XA[-1])\n",
    "            YA.append(YA[-1])\n",
    "            \n",
    "        T.append(i*dynamic_interval)\n",
    "    \n",
    "    print(dfm.iloc[-2:])\n",
    "    XA.append(dfm['X'].iloc[-2:].mean())\n",
    "    YA.append(dfm['Y'].iloc[-2:].mean())\n",
    "    T.append((i+1)*dynamic_interval)\n",
    "    \n",
    "    \n",
    "    data = {'X': XA, 'Y': YA, 'T': T}\n",
    "    dfp = pd.DataFrame(data)\n",
    "    dfp\n",
    "\n",
    "else:\n",
    "\n",
    "    print('len dfp was not greater than len dfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0fff7-f08b-4240-b59b-e8965d0cb786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ef841-857c-4d1a-8ead-9a0dfdabc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [255, 165, 0]\n",
    "\n",
    "for i in range(0,len(dfp)-1):\n",
    "\n",
    "    image_new = cv2.circle(image, (int(dfp['X'][i]),int(dfp['Y'][i])), 10, color, -1)\n",
    "    # image_new = cv2.arrowedLine(image_new, (int(dfm['X'][i]),int(dfm['Y'][i])), (int(dfm['X'][i+1]),int(dfm['Y'][i+1])), color, 2,tipLength = 0.001)\n",
    "#     image_new = cv2.putText(img, str(i), (int(dfm['X'][i]), int(dfm['Y'][i])), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(image_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e068c-8b4e-4097-b68b-9815509c711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Err_RG = []\n",
    "\n",
    "for i in range(0, len(df_GT)):\n",
    "    Err_RG.append(computeDistance((dfp['X'][i], dfp['Y'][i]), (df_GT['X'][i], df_GT['Y'][i])))\n",
    "\n",
    "Err_RG_scalded = [x * 33.4772/(955 - 130) for x in Err_RG] # Change it into the meter\n",
    "AveErr = np.mean(Err_RG_scalded)\n",
    "StdErr = np.std(Err_RG_scalded)\n",
    "print(AveErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6033e3-fe90-4d35-9479-96bd3a99c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Err_RG_scalded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9180e3-67b0-4dc8-8d43-6d836682e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_G = df_GT['X'].tolist()\n",
    "# Y_G = df_GT['Y'].tolist()\n",
    "# T_G = df_GT['T'].tolist()\n",
    "\n",
    "# X_P = dfp['X'].tolist()\n",
    "# Y_P = dfp['Y'].tolist()\n",
    "# T_P = dfp['T'].tolist()\n",
    "\n",
    "# data = {'XG': X_G, 'YG': Y_G, 'XP': X_P, 'YP': Y_P, 'Err': Err_RG_scalded,'TG': T_G, 'TP': T_P}\n",
    "# dft = pd.DataFrame(data)\n",
    "# dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047f521-b44e-4b84-a672-23e31cc56f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_G = df_GT['X'].tolist()\n",
    "Y_G = df_GT['Y'].tolist()\n",
    "\n",
    "X_P = dfp['X'].tolist()\n",
    "Y_P = dfp['Y'].tolist()\n",
    "\n",
    "data = {'XG': X_G, 'YG': Y_G, 'XP': X_P, 'YP': Y_P, 'Err': Err_RG_scalded}\n",
    "dft = pd.DataFrame(data)\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83581b-2714-4eef-98bd-4ee9c1f9b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft1 = dft['Err'].tolist()\n",
    "# dft2 = dft['Err'].tolist()\n",
    "# dft3 = dft['Err'].tolist()\n",
    "# dft4 = dft['Err'].tolist()\n",
    "# dft5 = dft['Err'].tolist()\n",
    "# dft6 = dft['Err'].tolist()\n",
    "# dft7 = dft['Err'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744aa73d-e244-48b6-989f-72a4decf5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data = {\n",
    "    'dft1': dft1,\n",
    "    'dft2': dft2,\n",
    "    'dft3': dft3,\n",
    "    'dft4': dft4,\n",
    "    'dft5': dft5,\n",
    "    'dft6': dft6,\n",
    "    'dft7': dft7\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd4656-a63f-4768-9645-855c38b3927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "# df.to_pickle('locationwise_error.pkl')\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "# df.to_pickle('locationwise_error_one_by_one.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f59010-b631-45d6-b48c-4a1411a68c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = pd.read_pickle('locationwise_error_one_by_one.pkl')\n",
    "df = df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75508412-33a3-4771-b150-06c6974bcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3afe7f-6a8b-4b34-942b-02114cf38fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can load it back like this to verify\n",
    "df_total = pd.read_pickle('locationwise_error_one_by_one.pkl')\n",
    "df = df_total\n",
    "\n",
    "\n",
    "# Plot each column as a line\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.plot(df[column], label=column)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Line Plot of dft Columns')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d4d8d-a1b5-444f-a9b0-63a4f7549963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can load it back like this to verify\n",
    "df_total = pd.read_pickle('locationwise_error.pkl')\n",
    "df = df_total\n",
    "\n",
    "\n",
    "# Plot each column as a line\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.plot(df[column][::-1].reset_index(drop=True), '-o', label=column)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Line Plot of dft Columns')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fee79-9b62-4610-93a5-0ecb56f4a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [f'BLE-{i}' for i in range(1, 8)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6a372-ef84-4e69-826e-b3ddc24bb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a modern style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Define region boundaries\n",
    "high_density_range = range(0, 8)  # First 7 indices\n",
    "low_density_range = range(8, 15)  # Last 7 indices\n",
    "\n",
    "# Add shaded regions\n",
    "plt.axvspan(0, 7, color='lightblue', alpha=0.3, label='High-Density Region')\n",
    "plt.axvspan(7, 14, color='lightgreen', alpha=0.3, label='Low-Density Region')\n",
    "\n",
    "# Plot the lines\n",
    "for column in df.columns:\n",
    "    plt.plot(df[column][::-1].reset_index(drop=True), \n",
    "             '-o', \n",
    "             label=column, \n",
    "             linewidth=2, \n",
    "             markersize=6)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Locations Along The Right Corridor', fontsize=14)\n",
    "plt.ylabel('Localization Error (Meters)', fontsize=14)\n",
    "plt.title('', fontsize=16)\n",
    "\n",
    "# Add a legend for both lines and regions\n",
    "plt.legend(title='', fontsize=12, title_fontsize=14, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotate the regions\n",
    "plt.text(3, max(df.max()) * 0.9, 'High Density', fontsize=18, color='blue', ha='center', alpha=0.8)\n",
    "plt.text(10.5, max(df.max()) * 0.9, 'Low Density', fontsize=18, color='green', ha='center', alpha=0.8)\n",
    "\n",
    "# Adjust layout and grid\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.savefig('error_trends_by_region.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790cf05-a6d2-49f2-8d77-240ed566751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft1_reversed = df_total['dft1'][::-1].reset_index(drop=True)\n",
    "dft7_reversed = df_total['dft7'][::-1].reset_index(drop=True)\n",
    "\n",
    "plt.plot(dft1_reversed, color = 'r', linewidth = 2)\n",
    "plt.plot(dft7_reversed, color = 'g', linewidth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad3386-96be-4ab8-a9e8-093b55a1bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataframes\n",
    "df1_total = pd.read_pickle('locationwise_error_one_by_one.pkl')\n",
    "df2_total = pd.read_pickle('locationwise_error.pkl')\n",
    "\n",
    "# Assume both dataframes have the same number of columns\n",
    "df1 = df1_total\n",
    "df2 = df2_total\n",
    "\n",
    "# Create subplots with as many rows as there are columns\n",
    "num_columns = len(df1.columns)\n",
    "fig, axs = plt.subplots(num_columns, 1, figsize=(8, 3 * num_columns))  # One column, as many rows as the columns of df1\n",
    "\n",
    "# Plot corresponding columns of both dataframes on the same subplot\n",
    "for i, column in enumerate(df1.columns):\n",
    "    # Plot df1's columns individually, cumulatively from the first to the current column\n",
    "    for col in df1.columns[:i+1]:\n",
    "        axs[i].plot(df1[col], '-or', linewidth = 1, label=f'df1 {col}')\n",
    "        \n",
    "    # Plot the current column of df2\n",
    "    axs[i].plot(df2[column], '-og', linewidth = 2, label=f'df2 {column}')\n",
    "    \n",
    "    axs[i].set_xlabel('Index')\n",
    "    axs[i].set_ylabel('Values')\n",
    "    axs[i].set_title(f'Plot of Columns Up to: {column}')\n",
    "    \n",
    "    # Move legend outside the plot\n",
    "    axs[i].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust layout to make space for the legends outside\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leave space on the right for the legends\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2db6f-7a91-43c6-bcda-4bfec28fc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can load it back like this to verify\n",
    "df_total = pd.read_pickle('locationwise_error_one_by_one.pkl')\n",
    "df = df_total\n",
    "\n",
    "\n",
    "# Z-score normalization\n",
    "# df_normalized_zscore = (df - df.mean()) / df.std()\n",
    "# df = df_normalized_zscore\n",
    "\n",
    "# df_normalized_minmax = (df - df.min()) / (df.max() - df.min())\n",
    "# df = df_normalized_minmax\n",
    "\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Normalize the color by setting vmin and vmax\n",
    "sns.heatmap(df, annot=True, cmap='YlOrBr', vmin=df.min().min(), vmax=df.max().max())\n",
    "\n",
    "# Add a title\n",
    "plt.title('Heatmap of dft Columns')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8103237-cc89-4b28-8200-e56c4beb6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can load it back like this to verify\n",
    "df_total = pd.read_pickle('locationwise_error.pkl')\n",
    "df = df_total\n",
    "\n",
    "\n",
    "# Z-score normalization\n",
    "# df_normalized_zscore = (df - df.mean()) / df.std()\n",
    "# df = df_normalized_zscore\n",
    "\n",
    "# df_normalized_minmax = (df - df.min()) / (df.max() - df.min())\n",
    "# df = df_normalized_minmax\n",
    "\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Normalize the color by setting vmin and vmax\n",
    "sns.heatmap(df, annot=True, cmap='YlOrBr', vmin=df.min().min(), vmax=df.max().max())\n",
    "\n",
    "# Add a title\n",
    "plt.title('Heatmap of dft Columns')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ffc5e-8c37-4adb-a719-396a78e595bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the DataFrame (already done)\n",
    "df_total = pd.read_pickle('locationwise_error.pkl')\n",
    "df = df_total\n",
    "# Rename columns\n",
    "df.rename(columns={'dft1': '#BLE-1', 'dft2': '#BLE-2', 'dft3': '#BLE-3', 'dft4': '#BLE-4', 'dft5': '#BLE-5', 'dft6': '#BLE-6', 'dft7': '#BLE-7'}, inplace=True)\n",
    "\n",
    "# Calculate statistics\n",
    "df_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Std': df.std(),\n",
    "    'Median': df.median(),\n",
    "    'Max': df.max(),\n",
    "    'Min': df.min()\n",
    "})\n",
    "\n",
    "cmap = plt.cm.copper_r  # Define colormap\n",
    "\n",
    "# First figure: Heatmap of the data\n",
    "fig1, ax1 = plt.subplots(figsize=(20, 5))\n",
    "sns.heatmap(df, annot=True, cmap=cmap, vmin=df.min().min(), vmax=df.max().max(), ax=ax1)\n",
    "\n",
    "# Reverse the y-axis and set y-ticks to start from 1\n",
    "ax1.invert_yaxis()  # Reverse the y-axis\n",
    "ax1.set_yticks(range(1, len(df.index) + 1))  # Set y-ticks to start from 1\n",
    "ax1.set_yticklabels(range(1, len(df.index) + 1))  # Label y-ticks from 1 to N\n",
    "\n",
    "ax1.set_title('Localization Error (m2) - Estimation Versus Ground Truth')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('heatmap_of_df_columns.png')  # Save as PNG\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig2, ax_array = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "# Plot each statistic in its own subplot\n",
    "for i, (stat, values) in enumerate(df_stats.items()):\n",
    "    # Normalize values for color mapping\n",
    "    norm = plt.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    colors = cmap(norm(values))  # Map colors based on values\n",
    "\n",
    "    # Plot each bar with color mapping\n",
    "    bars = ax_array[i].bar(values.index, values, color=colors)\n",
    "    ax_array[i].set_title(stat)\n",
    "    ax_array[i].set_ylabel('Err (m)')\n",
    "    ax_array[i].set_xlabel(' ')\n",
    "\n",
    "    # Overlay dot and line plots\n",
    "    ax_array[i].plot(values.index, values, marker='o', color='black', linestyle='-', linewidth=2, markersize=10)\n",
    "\n",
    "    # Set x-ticks to vertical position\n",
    "    ax_array[i].set_xticklabels(values.index, rotation=90)  # Set rotation to 90 degrees\n",
    "\n",
    "# Tight layout and display\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('statistics_bar_plots.png')  # Save as PNG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fa62b-065d-411b-af08-839393bcf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the DataFrame (already done)\n",
    "df_total = pd.read_pickle('locationwise_error.pkl')\n",
    "df = df_total\n",
    "# Rename columns\n",
    "df.rename(columns={'dft1': 'BLE-1', 'dft2': 'BLE-2', 'dft3': 'BLE-3', 'dft4': 'BLE-4', 'dft5': 'BLE-5', 'dft6': 'BLE-6', 'dft7': 'BLE-7'}, inplace=True)\n",
    "\n",
    "# Calculate statistics\n",
    "df_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Std': df.std(),\n",
    "    'Median': df.median(),\n",
    "    'Max': df.max(),\n",
    "    'Min': df.min()\n",
    "})\n",
    "\n",
    "cmap = plt.cm.copper_r  # Define colormap\n",
    "\n",
    "# Adjust font sizes globally\n",
    "plt.rcParams.update({'font.size': 16})  # General font size for all elements\n",
    "\n",
    "# First figure: Heatmap of the data\n",
    "fig1, ax1 = plt.subplots(figsize=(20, 8))\n",
    "sns.heatmap(df, annot=True, cmap=cmap, vmin=df.min().min(), vmax=df.max().max(), ax=ax1, annot_kws={'fontsize': 16})  # Increase annotation font size\n",
    "\n",
    "# Reverse the y-axis and set y-ticks to start from 1\n",
    "ax1.invert_yaxis()  # Reverse the y-axis\n",
    "ax1.set_yticks(range(1, len(df.index) + 1))  # Set y-ticks to start from 1\n",
    "ax1.set_yticklabels(range(1, len(df.index) + 1), fontsize=16, rotation=0)  # Make y-tick labels horizontal\n",
    "\n",
    "ax1.set_title('Localization Error (m2) - Estimation Versus Ground Truth', fontsize=16)  # Increase title font size\n",
    "ax1.set_xlabel(' ', fontsize=16)  # Increase x-axis label font size\n",
    "ax1.set_ylabel('Error', fontsize=16)  # Increase y-axis label font size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('heatmap_of_df_columns.png')  # Save as PNG\n",
    "plt.show()\n",
    "\n",
    "# Set up the figure and axes for statistics bar plots\n",
    "fig2, ax_array = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "# Plot each statistic in its own subplot\n",
    "for i, (stat, values) in enumerate(df_stats.items()):\n",
    "    # Normalize values for color mapping\n",
    "    norm = plt.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    colors = cmap(norm(values))  # Map colors based on values\n",
    "\n",
    "    # Plot each bar with color mapping\n",
    "    bars = ax_array[i].bar(values.index, values, color=colors)\n",
    "    ax_array[i].set_title(stat, fontsize=16)  # Increase subplot title font size\n",
    "    ax_array[i].set_ylabel('Err (m)', fontsize=16)  # Increase y-axis label font size\n",
    "    ax_array[i].set_xlabel(' ', fontsize=16)  # Increase x-axis label font size\n",
    "\n",
    "    # Overlay dot and line plots\n",
    "    ax_array[i].plot(values.index, values, marker='o', color='black', linestyle='-', linewidth=2, markersize=10)\n",
    "\n",
    "    # Set x-ticks to vertical position and increase font size\n",
    "    ax_array[i].set_xticklabels(values.index, rotation=90, fontsize=16)  # Set rotation and font size for x-tick labels\n",
    "\n",
    "# Tight layout and display\n",
    "plt.tight_layout()\n",
    "plt.savefig('statistics_bar_plots.png')  # Save as PNG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bc26d-6b3d-424e-a733-8bb8a608fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the DataFrame (already done)\n",
    "df_total = pd.read_pickle('locationwise_error.pkl')\n",
    "df = df_total\n",
    "\n",
    "# Calculate statistics\n",
    "df_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Std Dev': df.std(),\n",
    "    'Median': df.median(),\n",
    "    'Max': df.max(),\n",
    "    'Min': df.min()\n",
    "})\n",
    "\n",
    "# Reverse DataFrame and set new index starting from 1\n",
    "df_reversed = df.iloc[::-1]\n",
    "df_reversed.index = range(1, len(df_reversed) + 1)  # Set new index starting from 1\n",
    "\n",
    "# First figure: Heatmap of the data (reversed)\n",
    "fig1, ax1 = plt.subplots(figsize=(20, 5))\n",
    "sns.heatmap(df_reversed, annot=True, cmap='coolwarm', vmin=df.min().min(), vmax=df.max().max(), ax=ax1)\n",
    "\n",
    "# Reverse the y-axis labels\n",
    "ax1.set_yticks(range(1, len(df_reversed) + 1))  # Set y-ticks to start from 1\n",
    "ax1.set_yticklabels(range(len(df_reversed), 0, -1))  # Reverse labels from top to bottom\n",
    "\n",
    "ax1.set_title('Localization Error (m2) - Estimation Versus Ground Truth')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig2, ax_array = plt.subplots(1, 5, figsize=(20, 4))\n",
    "cmap = plt.cm.coolwarm  # Define colormap\n",
    "\n",
    "# Plot each statistic in its own subplot\n",
    "for i, (stat, values) in enumerate(df_stats.items()):\n",
    "    # Normalize values for color mapping\n",
    "    norm = plt.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    colors = cmap(norm(values))  # Map colors based on values\n",
    "\n",
    "    # Plot each bar with color mapping\n",
    "    bars = ax_array[i].bar(values.index, values, color=colors)\n",
    "    ax_array[i].set_title(stat)\n",
    "    ax_array[i].set_ylabel('Err (m)')\n",
    "    ax_array[i].set_xlabel(' ')\n",
    "\n",
    "    # Overlay dot and line plots\n",
    "    ax_array[i].plot(values.index, values, marker='o', color='black', linestyle='-', linewidth=2, markersize=10)\n",
    "\n",
    "# Adjust spacing between heatmap and bar plot\n",
    "plt.subplots_adjust(hspace=0.2)  # Decrease hspace to make it shorter\n",
    "\n",
    "# Tight layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Set up the figure and axes\n",
    "# fig2, ax_array = plt.subplots(1, 5, figsize=(20, 4))\n",
    "# cmap = plt.cm.coolwarm  # Define colormap\n",
    "\n",
    "# # Determine global min and max for normalization\n",
    "# global_min = min(df_stats[stat].min() for stat in df_stats)\n",
    "# global_max = max(df_stats[stat].max() for stat in df_stats)\n",
    "\n",
    "# # Plot each statistic in its own subplot\n",
    "# for i, (stat, values) in enumerate(df_stats.items()):\n",
    "#     # Normalize values for color mapping\n",
    "#     norm = plt.Normalize(vmin=global_min, vmax=global_max)\n",
    "#     colors = cmap(norm(values))  # Map colors based on values\n",
    "\n",
    "#     # Plot each bar with color mapping\n",
    "#     bars = ax_array[i].bar(values.index, values, color=colors)\n",
    "#     ax_array[i].set_title(stat)\n",
    "#     ax_array[i].set_ylabel('Err (m)')\n",
    "#     ax_array[i].set_xlabel(' ')\n",
    "\n",
    "#     # Overlay dot and line plots\n",
    "#     ax_array[i].plot(values.index, values, marker='o', color='black', linestyle='-', linewidth=2, markersize=10)\n",
    "\n",
    "#     # Set y-axis limits for the last subplot\n",
    "#     if i == 4:  # Last subplot (index 4)\n",
    "#         ax_array[i].set_ylim(0, 2)  # Set y-axis limits to 0 to 6\n",
    "\n",
    "# # Adjust spacing between heatmap and bar plot\n",
    "# plt.subplots_adjust(hspace=0.2)  # Decrease hspace to make it shorter\n",
    "\n",
    "# # Tight layout and display\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f60a7-d50d-4590-a0c0-f6311643f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(6, 3))  # Example: 10 inches wide, 6 inches tall\n",
    "\n",
    "# Plot the 'Err' values\n",
    "plt.plot(dft['Err'], '-ok', linewidth = 2, label='Error')\n",
    "\n",
    "# Calculate the average of 'Err'\n",
    "average_err = dft['Err'].mean()\n",
    "\n",
    "# Plot the average line\n",
    "plt.axhline(y=average_err, color='r', linestyle='--', linewidth = 2, label=f'Average: {average_err:.2f}')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error Plot with Average Line')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a22d2e-4b53-4416-bb5b-f2dec5931c35",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c36f1c-8992-411a-b932-58b85bb0d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_BLE_1 = [9.09, 7.59, 5.71, 5.37, 4.38, 4.13, 2.99]\n",
    "AVG_BLE_2 = [5.14, 4.46, 5.61, 4.97, 3.89, 2.89, np.nan]\n",
    "AVG_BLE_3 = [3.58, 3.92, 5.28, 4.99, 2.94, np.nan, np.nan]\n",
    "AVG_BLE_4 = [3.18, 3.74, 5.29, 3.17, np.nan, np.nan, np.nan]\n",
    "AVG_BLE_5 = [3.40, 3.75, 3.88, np.nan, np.nan, np.nan, np.nan]\n",
    "AVG_BLE_6 = [3.41, 2.90, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "AVG_BLE_7 = [2.72, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7819676-497e-43c2-8446-fa60d32f7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG = np.array([[AVG_BLE_1, AVG_BLE_2, AVG_BLE_3, AVG_BLE_4, AVG_BLE_5, AVG_BLE_6, AVG_BLE_7]])\n",
    "AVG = np.transpose(AVG)\n",
    "AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa3f12-c36b-4dc3-8333-b052c4e6cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "lw, ms = 1, 5\n",
    "x = list(range(1, 8))\n",
    "plt.plot(x, AVG[0][0], '-ok', markersize = ms, linewidth = lw, label='# of BLE = 1')\n",
    "plt.plot(x, AVG[0][1], '-or', markersize = ms, linewidth = lw, label='# of BLE = 2')\n",
    "plt.plot(x, AVG[0][2], '-ob', markersize = ms, linewidth = lw, label='# of BLE = 3')\n",
    "plt.plot(x, AVG[0][3], '-om', markersize = ms, linewidth = lw, label='# of BLE = 4')\n",
    "plt.plot(x, AVG[0][4], '-oy', markersize = ms, linewidth = lw, label='# of BLE = 5')\n",
    "plt.plot(x, AVG[0][5], '-oc', markersize = ms, linewidth = lw, label='# of BLE = 6')\n",
    "plt.plot(x, AVG[0][6], '-og', markersize = ms, linewidth = lw, label='# of BLE = 7')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.xlabel('Total Number of Cases')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94840562-a212-40c9-baf7-e8f70276b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "lw, ms = 1, 5\n",
    "x = list(range(1, 8))\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.plot(x, AVG[0], '-ok', markersize = ms, linewidth = lw)\n",
    "# plt.plot(x, AVG[1], '-or', markersize = ms, linewidth = lw)\n",
    "# plt.plot(x, AVG[2], '-ob', markersize = ms, linewidth = lw)\n",
    "# plt.plot(x, AVG[3], '-om', markersize = ms, linewidth = lw)\n",
    "# plt.plot(x, AVG[4], '-oy', markersize = ms, linewidth = lw)\n",
    "plt.plot(x, AVG[5], '-oc', markersize = ms, linewidth = lw)\n",
    "# plt.plot(x , AVG[6], '-og', markersize = ms, linewidth = lw)\n",
    "\n",
    "plt.xlim([0.8, 7.2])\n",
    "plt.ylim([2., 10])\n",
    "plt.xlabel('Number of BLE Devices')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877061e-8b7a-4a70-9b03-56c259cfb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [9.09, 7.59, 5.71, 5.37, 4.38, 4.13, 2.99],\n",
    "    [5.14, 4.46, 5.61, 4.97, 3.89, 2.89, np.nan],\n",
    "    [3.58, 3.92, 5.28, 4.99, 2.94, np.nan, np.nan],\n",
    "    [3.18, 3.74, 5.29, 3.17, np.nan, np.nan, np.nan],\n",
    "    [3.40, 3.75, 3.88, np.nan, np.nan, np.nan, np.nan],\n",
    "    [3.41, 2.90, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    [2.72, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea809e1-4613-4cea-a7ed-291638e98722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    [9.09, 7.59, 5.71, 5.37, 4.38, 4.13, 2.99],\n",
    "    [5.14, 4.46, 5.61, 4.97, 3.89, 2.89, np.nan],\n",
    "    [3.58, 3.92, 5.28, 4.99, 2.94, np.nan, np.nan],\n",
    "    [3.18, 3.74, 5.29, 3.17, np.nan, np.nan, np.nan],\n",
    "    [3.40, 3.75, 3.88, np.nan, np.nan, np.nan, np.nan],\n",
    "    [3.41, 2.90, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    [2.72, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "# Extract the first column and handle NaN values\n",
    "first_column = [row[0] for row in data]\n",
    "\n",
    "# Define the number of BLE devices (1 to 7 for this example)\n",
    "ble_devices = list(range(1, len(first_column) + 1))\n",
    "\n",
    "# Create a figure with a larger size\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "# Add horizontal and vertical lines\n",
    "plt.axhline(y=3.5, color='red', linestyle='--', linewidth=3)\n",
    "plt.axvline(x=3, color='green', linestyle='--', linewidth=3)\n",
    "\n",
    "# Plot the first column with enhanced styling\n",
    "plt.plot(ble_devices, first_column, marker='o', color='black', markersize=8, linestyle='-', linewidth=2, label='Error Measurement')\n",
    "\n",
    "# Set labels and title with larger font sizes\n",
    "plt.xlabel('Number of BLE Devices', fontsize=14)\n",
    "plt.ylabel('Error in Meters', fontsize=14)\n",
    "plt.title('Error in Meters vs Number of BLE Devices', fontsize=16)\n",
    "\n",
    "# Set x-ticks to match the number of BLE devices\n",
    "plt.xticks(ble_devices, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "# Set limits on the axes if necessary (adjust based on your data)\n",
    "plt.ylim(0, max([val for val in first_column if not np.isnan(val)]) + 1)  # Set the y-limit based on your data\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout for better\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('Error_in_Meters_vs_Number_of_BLE_Devices.png', dpi=300, bbox_inches='tight')  # Save as PNG with 300 DPI\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a4e97-3252-442f-996b-48829129889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    [9.09, 7.59, 5.71, 5.37, 4.38, 4.13, 2.99],\n",
    "    [5.14, 4.46, 5.61, 4.97, 3.89, 2.89, np.nan],\n",
    "    [3.58, 3.92, 5.28, 4.99, 2.94, np.nan, np.nan],\n",
    "    [3.18, 3.74, 5.29, 3.17, np.nan, np.nan, np.nan],\n",
    "    [3.40, 3.75, 3.88, np.nan, np.nan, np.nan, np.nan],\n",
    "    [3.41, 2.90, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    [2.72, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "# Convert the data to a numpy array\n",
    "data_array = np.array(data).T\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.heatmap(data_array, annot=True, fmt=\".2f\", cmap='YlOrBr_r', \n",
    "                 cbar=True, mask=np.isnan(data_array), linewidths=2, linecolor='white')\n",
    "\n",
    "# Hide x-axis and y-axis\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Optionally hide axis labels if you want no labels at all\n",
    "plt.xlabel('Number of BLE devices')\n",
    "plt.ylabel('Error (meters)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('Heatmap_Error_in_Meters_vs_Number_of_BLE_Devices.png', dpi=300, bbox_inches='tight')  # Save as PNG with 300 DPI\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c742ee9-25bb-4fcd-b897-44766163d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    [9.09, 7.59, 5.71, 5.37, 4.38, 4.13, 2.99],\n",
    "    [5.14, 4.46, 5.61, 4.97, 3.89, 2.89, np.nan],\n",
    "    [3.58, 3.92, 5.28, 4.99, 2.94, np.nan, np.nan],\n",
    "    [3.18, 3.74, 5.29, 3.17, np.nan, np.nan, np.nan],\n",
    "    [3.40, 3.75, 3.88, np.nan, np.nan, np.nan, np.nan],\n",
    "    [3.41, 2.90, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    [2.72, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "# Convert the data to a numpy array\n",
    "data_array = np.array(data).T\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.heatmap(data_array, annot=True, fmt=\".2f\", cmap='YlOrBr_r', \n",
    "                 cbar=True, mask=np.isnan(data_array), linewidths=2, linecolor='white')\n",
    "\n",
    "# Access the color bar and move ticks to the left\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.yaxis.set_ticks_position('left')  # Move ticks to the left\n",
    "\n",
    "# Hide x-axis and y-axis\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Optionally hide axis labels if you want no labels at all\n",
    "plt.xlabel('Number of BLE devices')\n",
    "plt.ylabel('Error (meters)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('Heatmap_Error_in_Meters_vs_Number_of_BLE_Devices.png', dpi=300, bbox_inches='tight')  # Save as PNG with 300 DPI\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10104a-8cec-4faa-8932-ac83f9c0555c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chagas",
   "language": "python",
   "name": "chagas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
